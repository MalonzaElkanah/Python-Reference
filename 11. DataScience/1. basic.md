# DATA SCIENCE
- Data science generally refers to the process of working out insights from large datasets of unstructured data. This means using predicative analytics, statistics and machine learning to wade through the mass of data.

## Data analytics 
- The process of gaining insights in data
- This primarily focuses on using and creating statistical analysis for existing sets of data to achieve insights on that data.


## Big data 
- This is a term used to referto large and complex datasets that are too large for traditional data processing software (read databases, spread sheets, and traditional statistics packages like SPSS) to handle.
- Their are three different concepts, called the “Three V’s”: 
	1. volume, 
	2. variety, and 
	3. velocity.

### Volume
This refers to how big the dataset is that we are considering.

### Variety
This are the different type of data. Example: Photo, Humidity, Audio, 

### Velocity
Velocity refers to how fast the data is changing and how fast it is being added to the data piles.


## The Five Step Process of Data Science
1. Capture the data
2. Process the data
3. Analyze the data
4. Communicate the results
5. Maintain the data

### Capture Data
- To have something to do analysis on, you have to capture some data. 
- You probably have a number of potential sources of data. 
- Inventory them and decide what to include according to the goals of the upcoming analysis.

### Process Data
- You need to identify anomalies and outliers, eliminate duplicates, remove missing entries, and figure out what data is inconsistent. 
- Cleaning and processing your data needs to be done carefully or else you will bias and maybe destroy the ability to do good inferences or get good answers down the line.

### Analyze Data
- Analyzing big datasets for insights and inferences or even asking complex questions is the hardest challenge, one that requires the most human intuition in all of data science. 
- Example of question, “How can I get more people to buy Sugar Frosted Flakes?”
- Analyzing the data requires skill and experience in statistics techniques like linear and logistic regressions and finding correlations between different data types by using a variety of probability algorithms and formulas such as the incredibly coolly named “Naïve Bayes” formulas and concepts.

### Communicating the Data
- Most people visualize information better and faster when they see it in a graphical format rather than just in text.

### Maintaining the Data
- It's important to archive and document the following information so you can restart the project quickly, or even more likely in the future you will run across a similar set of problems and can quickly dust the models off and get to answers faster.
- Take time to preserve:
	1. The data and sources
	2. The models you used to modify the data (including any exception data and “data throw-out criteria” you used)
	3. The queries and results you got from the queries



# Big Data with Python
Python based tools and processes used by data scientists to format, process, and query their data
1. NumPy
2. Pandas
3. MatPlotLib

## NumPy
- NumPy adds big data-manipulation tools to Python such as large-array manipulation and high-level mathematical functions for data science. 
- NumPy is best at handling basic numerical computation such as means, averages, and so on. It also
excels at the creation and manipulation of multidimensional arrays known as tensors or matrices
*Example: Building a 2 * 2 Matrix*

	import numpy as np
	x = np.array([[1,2],[3,4]])
	print(np.sum(x)) # Compute sum of all elements; prints "10"
	print(np.sum(x, axis=0)) # Compute sum of each column; prints "[4 6]"
	print(np.sum(x, axis=1)) # Compute sum of each row; prints "[3 7]"


## Pandas
- Pandas provides fast, flexible, and expressive data structures to make working with relational or labeled data more intuitive.
- It performs well with tabular type of data (such as SQL tables or Excel spreadsheets) and is really good with time-series data (like, say, temperatures taken on a hourly basis).
- Pandas DataFrames are a way to store data in rectangular grids that can easily be overviewed.


## MatPlotLib
- It provides a Python object-oriented API for embedded plots into applications using general-purpose GUI interfaces. 
- You can make elaborate and professional-looking graphs, and even build “live” graphs that update while your application is running.
- This can be handy in machine-learning applications and data-analysis applications, where it is good to see the system making progress towards some goal.
